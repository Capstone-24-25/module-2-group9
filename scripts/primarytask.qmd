---
title: "primarytask"
format: html
editor: visual
---

## Primary task

benchmark: accuracy: 0.835 roc_auc: 0.878

Attempt to use NN to reach similar or better result

```{r}
#install.packages("text")
library(tidyverse)
library(tidymodels)
library(tidytext)
library(keras)
library(tensorflow)
library(text)
require(textstem)
require(rvest)
require(qdapRegex)
require(stopwords)
require(tokenizers)
library(reticulate)
library(purrr)

# install_keras(tensorflow = "2.16")
```

```{r}
# predefined functions
# function to parse html and clean text
parse_fn <- function(.html){
  read_html(.html) %>%
    html_elements('p, h1, h2, h3, h4, h5') %>% # Include header for better result, product of trial and error
    html_text2() %>%
    str_c(collapse = ' ') %>%
    rm_url() %>%
    rm_email() %>%
    str_remove_all('\'') %>%
    str_replace_all(paste(c('\n', 
                            '[[:punct:]]', 
                            'nbsp', 
                            '[[:digit:]]', 
                            '[[:symbol:]]'),
                          collapse = '|'), ' ') %>%
    str_replace_all("([a-z])([A-Z])", "\\1 \\2") %>%
    tolower() %>%
    str_replace_all("\\s+", " ")
}

# function to apply to claims data
parse_data <- function(.df){
  out <- .df %>%
    filter(str_detect(text_tmp, '<!')) %>%
    rowwise() %>%
    mutate(text_clean = parse_fn(text_tmp)) %>%
    unnest(text_clean) 
  return(out)
}

nlp_fn <- function(parse_data.out){
  out <- parse_data.out %>% 
    unnest_tokens(output = token, 
                  input = text_clean, 
                  token = 'words',
                  stopwords = str_remove_all(stop_words$word, 
                                             '[[:punct:]]')) %>%
    mutate(token.lem = lemmatize_words(token)) %>%
    filter(str_length(token.lem) > 2) %>%
    count(.id, bclass, token.lem, name = 'n') %>%
    bind_tf_idf(term = token.lem, 
                document = .id,
                n = n) %>%
    pivot_wider(id_cols = c('.id', 'bclass'),
                names_from = 'token.lem',
                values_from = 'tf_idf',
                values_fill = 0)
  return(out)
}


# Load and parse the data
# load raw data
load('../data/claims-raw.RData')

# preprocess (will take a minute or two)
claims_clean <- claims_raw %>%
  parse_data()

claims_clean = claims_clean %>% 
  select(.id, mclass, bclass, text_clean)

```

We now have cleaned texts, which is claims_clean. This will be our starting point

```{r}
# Tokenize and construct the tf_idf term matrix
claims_clean_tfidf = claims_clean %>%
  mutate(text_clean = str_trim(text_clean)) %>%
  filter(str_length(text_clean) > 5) %>%
  unnest_tokens(output = 'token', 
                input = text_clean) %>%
  group_by(.id, bclass, mclass) %>%
  count(token) %>%
  bind_tf_idf(term = token, 
              document = .id, 
              n = n) %>%
  pivot_wider(id_cols = c(.id, bclass, mclass), 
              names_from = token, 
              values_from = tf_idf,
              values_fill = 0) %>%
  ungroup() 

# Load a list of stop words
stopwords_nopunct <- stopwords(language = 'en', source = 'snowball') %>% 
  str_remove_all('[[:punct:]]')

# Remove stop words
claims_clean_tfidf <- claims_clean_tfidf[, !names(claims_clean_tfidf) %in% stopwords_nopunct]

```

##### binary class

```{r}
# partition
set.seed(111524)
partitions <- claims_clean_tfidf %>%
  initial_split(prop = 0.8)

x_train = training(partitions) %>% 
  select(-mclass, -bclass, -.id) %>% 
  as.matrix

y_train = training(partitions) %>% 
  pull(bclass) %>% 
  factor() %>% 
  as.numeric() - 1
binary_levels = levels(training(partitions) %>% pull(bclass) %>% factor())

x_test = testing(partitions) %>% 
  select(-mclass, -bclass, -.id) %>% 
  as.matrix()

y_test = testing(partitions) %>% 
  pull(bclass) %>% 
  factor() %>% 
  as.numeric() - 1
  
```

```{r}
set.seed(111524)
# Specify model type
library(keras3)

# Model building
binary_model <- keras_model_sequential(input_shape = ncol(x_train)) %>%
  layer_dense(256) %>%
  layer_dense(256) %>% 
  layer_dense(1) %>%
  layer_activation(activation = 'sigmoid')

summary(binary_model)

# Save the binary class model
# saveRDS(binary_model, file = "../results/binary_model.rds")
```

```{r}
set.seed(111524)
# compile the model
binary_model %>%
  compile(
    loss = 'binary_crossentropy',
    optimizer = optimizer_adam(),
    metrics = list('binary_accuracy',  metric_auc())
  )
```

```{r}
set.seed(111524)
# Fit the model, with 10 epoch, and cross validation with validation split of 0.2
history <- binary_model %>%
  fit(x = x_train,
      y = y_train,
      epochs = 6)
```

###### Evaluate prediction

```{r}
# Evaluate accuracy on testing set
library(yardstick)
library(tibble)

test_results = data.frame(truth = as.factor(y_test), prediction = predict(binary_model, x_test)) %>% 
  mutate(prediction = as.factor(ifelse(prediction > 0.5, 1, 0)))

test_metrics = accuracy(test_results, truth = truth, estimate = prediction) %>% 
  rbind(sens(test_results, truth = truth, estimate = prediction)) %>% 
  rbind(spec(test_results, truth = truth, estimate = prediction))
  


```

Our testing accuracy in theh etstin gdata is 0.82, which is the best we can obtain.

###### Make predictions on testing dataset

```{r}
# Import the claims_test dataset
load('../data/claims-test.RData')

# Clean clains_test
claims_test_clean <- claims_test %>%
  parse_data()
claims_test_clean = claims_test_clean %>% 
  select(.id, text_clean)

# Notice there are 19 observations with an empty string, we cannot predict any value from that
# This issue may be from the parsing but we will investigate later
claims_test_clean %>% filter(text_clean == "")

# Tokenize and construct the tf_idf term matrix
claims_test_tfidf = claims_test_clean %>%
  mutate(text_clean = str_trim(text_clean)) %>% 
  unnest_tokens(output = 'token', 
                input = text_clean) %>% 
  group_by(.id) %>%
  count(token) %>%
  bind_tf_idf(term = token, 
              document = .id, 
              n = n) %>%
  pivot_wider(id_cols = c(.id), 
              names_from = token, 
              values_from = tf_idf,
              values_fill = 0) %>%
  ungroup() 

# Load a list of stop words
stopwords_nopunct <- stopwords(language = 'en', source = 'snowball') %>% 
  str_remove_all('[[:punct:]]')

# Remove stop words
claims_test_tfidf <- claims_test_tfidf[, !names(claims_test_tfidf) %in% stopwords_nopunct]

# Align the dimension of claims_test_tfidf claims_clean_tfidf
claims_test_tfidf = claims_test_tfidf %>%
  bind_cols(as.data.frame(matrix(0, nrow = nrow(claims_test_tfidf), 
                                 ncol = length(setdiff(names(claims_clean_tfidf), names(claims_test_tfidf))), 
                                 dimnames = list(NULL, setdiff(names(claims_clean_tfidf), names(claims_test_tfidf)))))) %>%
  select(all_of(names(claims_clean_tfidf))) %>% 
  select(-bclass, -mclass)

```

```{r}
# Make predictions on the testing data
claims_test_tfidf_id = claims_test_tfidf %>% select(.id)
claims_test_tfidf_predictor = claims_test_tfidf %>% select(-.id) %>% as.matrix() ###### use this directly for multiclass 

# Save the testing data
# save(claims_test_tfidf_predictor, file = "../data/clean_test.RData")

binary_prediction = binary_model %>% predict(claims_test_tfidf_predictor)

pred_df = claims_test_tfidf_id %>% 
  mutate(bclass.pred = binary_prediction) %>% 
  mutate(bclass.pred = ifelse(bclass.pred > 0.5, 2, 1)) %>% 
  mutate(bclass.pred = binary_levels[bclass.pred])
```

##### multi class

```{r}
# partition
set.seed(111524)
partitions <- claims_clean_tfidf %>%
  initial_split(prop = 0.8)

x_train = training(partitions) %>% 
  select(-mclass, -bclass, -.id) %>% 
  as.matrix

y_train = training(partitions) %>% 
  pull(mclass) %>% 
  factor() %>% 
  as.numeric() - 1
multiclass_levels = levels(training(partitions) %>% pull(mclass) %>% factor())

x_test = testing(partitions) %>% 
  select(-mclass, -bclass, -.id) %>% 
  as.matrix()

y_test = testing(partitions) %>% 
  pull(mclass, bclass) %>% 
  factor() %>% # use as.matrix for multiclass
  as.numeric() - 1
  
```

```{r}
# Specify model type
library(keras3)

# Model building
multi_model <- keras_model_sequential(input_shape = ncol(x_train)) %>%
  layer_dense(256) %>%
  layer_dense(256) %>% 
  layer_dense(5) %>%
  layer_activation(activation = 'softmax')

summary(multi_model)

# Save the multi class model
# saveRDS(multi_model, file = "../results/multi_model.rds")
```

```{r}
# compile the model
multi_model %>%
  compile(
    loss = 'sparse_categorical_crossentropy',
    optimizer = optimizer_adam(),
    metrics = list('sparse_categorical_accuracy')
  )
```

```{r}
# Fit the model, with 10 epoch, and cross validation with validation split of 0.2
history <- multi_model %>%
  fit(x = x_train,
      y = y_train,
      epochs = 6)
```

###### Evaluate prediction

```{r}
# Evaluate accuracy on testing set
library(yardstick)
library(tibble)
test_results = data.frame(truth = y_test) %>% 
  data.frame(predict(multi_model, x_test)) %>% 
  rowwise() %>% 
  mutate(prediction = which.max(c_across(X1:X5))) %>%
  ungroup() %>% 
  mutate(prediction = factor(prediction - 1)) %>% 
  mutate(truth = factor(truth)) %>% 
  select(truth, prediction) 

test_metrics = accuracy(test_results, truth = truth, estimate = prediction) %>% 
  rbind(sens(test_results, truth = truth, estimate = prediction)) %>% 
  rbind(spec(test_results, truth = truth, estimate = prediction))
```

We reached 80% sparse categorical accuracy on the testing data

###### Make predictions on testing dataset

```{r}
multiclass_prediction = multi_model %>% predict(claims_test_tfidf_predictor)

pred_df = pred_df %>% 
  cbind(data.frame(multiclass_prediction)) %>% 
  rowwise() %>% 
  mutate(mclass.pred = which.max(c_across(X1:X5))) %>%
  ungroup() %>% 
  select(.id, bclass.pred, mclass.pred) %>% 
  mutate(mclass.pred = multiclass_levels[mclass.pred])

# Save the results
#save(pred_df, file = "../results/preds-group[N].RData")

```
